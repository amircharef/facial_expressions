{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdbe3fb",
   "metadata": {},
   "source": [
    "# TP4 - Classification des expressions faciales avec un CNN (PyTorch)\n",
    "Dans ce TP, vous allez entraîner un **réseau de neurones convolutionnel (CNN)** pour reconnaître les **expressions faciales** à partir d’images en niveaux de gris.\n",
    "\n",
    "**Objectifs :**\n",
    "- Charger un dataset d’images faciales\n",
    "- Prétraiter les images (redimensionnement, normalisation)\n",
    "- Construire un CNN\n",
    "- Entraîner et évaluer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bf03f",
   "metadata": {},
   "source": [
    "## Étape 1 - Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6337f9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "\n",
    "class FacialExpressionDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.root_dir / self.annotations.iloc[idx, 0]\n",
    "        label = int(self.annotations.iloc[idx, 1])\n",
    "        image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ddb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "csv_file = 'facial_expressions/data/legend.csv'\n",
    "root_dir = 'facial_expressions/data'\n",
    "\n",
    "dataset = FacialExpressionDataset(csv_file=csv_file, root_dir=root_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbde55",
   "metadata": {},
   "source": [
    "## Étape 2 - Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba265516",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './facial_expressions/data/images'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72072d",
   "metadata": {},
   "source": [
    "## Étape 3 - Affichage de quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b37108",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.title(f\"{labels[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88695c09",
   "metadata": {},
   "source": [
    "## Étape 4 - Définir le CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FacialCNN, self).__init__()\n",
    "        # TODO: définir les couches convolutionnelles et fully connected\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: définir la passe avant\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52175033",
   "metadata": {},
   "source": [
    "## Étape 5 - Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651113fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: instancier le modèle, la loss et l'optimizer\n",
    "model = FacialCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for images, labels in train_loader:\n",
    "        # TODO: forward + backward + step\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e6e00",
   "metadata": {},
   "source": [
    "## Étape 6 - Évaluer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mesurer la précision du modèle sur l'ensemble de validation\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
